

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://localhost:4000/</id>
  <title>YUN-JAEYEONG</title>
  <subtitle>A minimal, responsive and feature-rich Jekyll theme for technical writing.</subtitle>
  <updated>2026-02-01T19:30:12+09:00</updated>
  <author>
    <name>YUN JAEYEONG</name>
    <uri>http://localhost:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://localhost:4000/"/>
  <generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator>
  <rights> © 2026 YUN JAEYEONG </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>벨만 방정식(bellman equation, ベルマン方程式)</title>
    <link href="http://localhost:4000/posts/%EB%B2%A8%EB%A7%8C-%EB%B0%A9%EC%A0%95%EC%8B%9D(%E3%83%99%E3%83%AB%E3%83%9E%E3%83%B3%E6%96%B9%E7%A8%8B%E5%BC%8F)/" rel="alternate" type="text/html" title="벨만 방정식(bellman equation, ベルマン方程式)" />
    <published>2026-02-01T16:00:00+09:00</published>
  
    <updated>2026-02-01T16:00:00+09:00</updated>
  
    <id>http://localhost:4000/posts/%EB%B2%A8%EB%A7%8C-%EB%B0%A9%EC%A0%95%EC%8B%9D(%E3%83%99%E3%83%AB%E3%83%9E%E3%83%B3%E6%96%B9%E7%A8%8B%E5%BC%8F)/</id>
    <content type="text/html" src="http://localhost:4000/posts/%EB%B2%A8%EB%A7%8C-%EB%B0%A9%EC%A0%95%EC%8B%9D(%E3%83%99%E3%83%AB%E3%83%9E%E3%83%B3%E6%96%B9%E7%A8%8B%E5%BC%8F)/" />
    <author>
      <name>YUN JAEYEONG</name>
    </author>

  
    
    <category term="강화학습" />
    
    <category term="強化学習" />
    
  

  <summary>벨만 방정식(ベルマン方程式)  확률과 기댓값(確率と期待値)  각각의 눈이 나올 확률이 정확하게 \(\frac{1}{6}\)씩인 이상적인 주사위임을 가정하면, 각 확률은 다음 식으로 표현할 수 있다.  各目が出る確率が正確にそれぞれ\(\frac{1}{6}\)である理想的なサイコロを仮定すると、各確率は次の式で表される。  [p(x) = \frac{1}{6}]  주사위를 굴렸을 때 나올 기댓값은 다음과 같이 구할 수 있다.  サイコロを振った時に得られる期待値は、次のように計算できる。  \(E[x] = 1\times\frac{1}{6}+2\times\frac{1}{6}+3\times\frac{1}{6}+4\times\frac{1}{6}+5\times\frac{1}{6}+6\times\frac{1}{6}\\=3.5\) 조...</summary>

  </entry>

  
  <entry>
    <title>마르코프 결정 과정(MDP, マルコフ決定過程)</title>
    <link href="http://localhost:4000/posts/%EB%A7%88%EB%A5%B4%EC%BD%94%ED%94%84-%EA%B2%B0%EC%A0%95-%EA%B3%BC%EC%A0%95(MDP,-%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E6%B1%BA%E5%AE%9A%E9%81%8E%E7%A8%8B)/" rel="alternate" type="text/html" title="마르코프 결정 과정(MDP, マルコフ決定過程)" />
    <published>2026-01-28T16:00:00+09:00</published>
  
    <updated>2026-01-28T16:00:00+09:00</updated>
  
    <id>http://localhost:4000/posts/%EB%A7%88%EB%A5%B4%EC%BD%94%ED%94%84-%EA%B2%B0%EC%A0%95-%EA%B3%BC%EC%A0%95(MDP,-%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E6%B1%BA%E5%AE%9A%E9%81%8E%E7%A8%8B)/</id>
    <content type="text/html" src="http://localhost:4000/posts/%EB%A7%88%EB%A5%B4%EC%BD%94%ED%94%84-%EA%B2%B0%EC%A0%95-%EA%B3%BC%EC%A0%95(MDP,-%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E6%B1%BA%E5%AE%9A%E9%81%8E%E7%A8%8B)/" />
    <author>
      <name>YUN JAEYEONG</name>
    </author>

  
    
    <category term="강화학습" />
    
    <category term="強化学習" />
    
  

  <summary>마르코프 결정 과정(MDP, マルコフ決定過程)  결정 과정（決定過程）  ‘결정 과정’이란 ‘에이전트가 (환경과 상호작용하면서) 행동을 결정하는 과정’을 뜻한다.  에이전트가 행동을 취함으로써 상태가 변하며, 보상도 달라진다.  「決定過程」とは、「エージェントが（環境と相互作用しながら）行動を決定する過程」を指す。  エージェントが行動を取ることによって状態が変化し、それに伴って報酬も変化する。   \(S_0,A_0,R_0,S_1,S_1,R_1,S_2,A_2,R_2,\cdots\)  에이전트와 환경의 상호작용은 위와 같은 전이를 만들어낸다.  エージェントと環境の相互作用は、上記のような遷移を生み出す  상태전이（状態遷移）  상태 전이 함수(状態遷移関数)                 [p(s’       s,a)]       ...</summary>

  </entry>

  
  <entry>
    <title>밴디트 문제(バンディット問題)</title>
    <link href="http://localhost:4000/posts/%EB%B0%B4%EB%94%94%ED%8A%B8-%EB%AC%B8%EC%A0%9C(%E3%83%90%E3%83%B3%E3%83%87%E3%82%A3%E3%83%83%E3%83%88%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0)/" rel="alternate" type="text/html" title="밴디트 문제(バンディット問題)" />
    <published>2026-01-27T19:00:00+09:00</published>
  
    <updated>2026-01-28T16:22:49+09:00</updated>
  
    <id>http://localhost:4000/posts/%EB%B0%B4%EB%94%94%ED%8A%B8-%EB%AC%B8%EC%A0%9C(%E3%83%90%E3%83%B3%E3%83%87%E3%82%A3%E3%83%83%E3%83%88%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0)/</id>
    <content type="text/html" src="http://localhost:4000/posts/%EB%B0%B4%EB%94%94%ED%8A%B8-%EB%AC%B8%EC%A0%9C(%E3%83%90%E3%83%B3%E3%83%87%E3%82%A3%E3%83%83%E3%83%88%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0)/" />
    <author>
      <name>YUN JAEYEONG</name>
    </author>

  
    
    <category term="강화학습" />
    
    <category term="強化学習" />
    
  

  <summary>밴디트 문제(バンディット問題)  머신러닝의 분류（機械学習の分類）          지도 학습:정답이 있는 데이터를 활용해 데이터를 학습           비지도 학습:정답 레이블이 없는 데이터를 군집화 하는 학습           강화 학습:에이전트가 환경과 상호작용하면서 수집한 데이터를 바탕으로 더 많은 보상을 얻는 방법 학습      ㅤ      教師あり学習：正解ラベル付きデータを用いて学習する手法   教師なし学習：正解ラベルのないデータをクラスタリングする学習   強化学習：エージェントが環境と相互作用しながら得たデータを基に，より多くの報酬を得る方法を学習する手法   밴디트 문제（バンディット問題）  슬롯머신 = 환경  スロットマシン＝環境  플레이어 = 에이전트  プレイヤー＝エージェント  좋은 슬롯 머신이란?（良いスロ...</summary>

  </entry>

  
  <entry>
    <title>강화학습(強化学習)</title>
    <link href="http://localhost:4000/posts/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5(%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92)/" rel="alternate" type="text/html" title="강화학습(強化学習)" />
    <published>2026-01-26T19:00:00+09:00</published>
  
    <updated>2026-01-26T19:00:00+09:00</updated>
  
    <id>http://localhost:4000/posts/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5(%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92)/</id>
    <content type="text/html" src="http://localhost:4000/posts/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5(%E5%BC%B7%E5%8C%96%E5%AD%A6%E7%BF%92)/" />
    <author>
      <name>YUN JAEYEONG</name>
    </author>

  
    
    <category term="강화학습" />
    
    <category term="強化学習" />
    
  

  <summary>강화학습(強化学習)  밑바닥부터 시작하는 딥러닝 4 책을 이용해서 강화학습에 대해 공부합니다!  ゼロから作るdeep learning 4　本を見て強化学習について勉強します！</summary>

  </entry>

</feed>


